# Author: QuanTuanHuy
# Description: Part of Serp Project - Alembic Script Template

"""initial schema

Revision ID: 07684dff26b7
Revises: 
Create Date: 2025-11-06 12:31:32.289068

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import pgvector.sqlalchemy

# revision identifiers, used by Alembic.
revision: str = '07684dff26b7'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # Enable pgvector extension
    op.execute('CREATE EXTENSION IF NOT EXISTS vector')
    
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('ai_modules',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('code', sa.String(length=50), nullable=False),
    sa.Column('name', sa.String(length=100), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('icon', sa.String(length=50), nullable=True),
    sa.Column('enabled', sa.Boolean(), nullable=False),
    sa.Column('config', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_ai_modules_code'), 'ai_modules', ['code'], unique=True)
    op.create_table('document_chunks',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('tenant_id', sa.BigInteger(), nullable=False),
    sa.Column('module_code', sa.String(length=50), nullable=False),
    sa.Column('source_type', sa.String(length=50), nullable=False),
    sa.Column('source_id', sa.BigInteger(), nullable=False),
    sa.Column('chunk_index', sa.Integer(), nullable=False),
    sa.Column('content', sa.Text(), nullable=False),
    sa.Column('embedding', pgvector.sqlalchemy.Vector(dim=768), nullable=False),
    sa.Column('token_count', sa.Integer(), nullable=True),
    sa.Column('meta_data', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('indexed_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('tenant_id', 'module_code', 'source_type', 'source_id', 'chunk_index', name='uq_chunk_source_index')
    )
    op.create_index('idx_chunks_source', 'document_chunks', ['source_type', 'source_id'], unique=False)
    op.create_index('idx_chunks_tenant_module', 'document_chunks', ['tenant_id', 'module_code'], unique=False)
    op.create_index(op.f('ix_document_chunks_module_code'), 'document_chunks', ['module_code'], unique=False)
    op.create_index(op.f('ix_document_chunks_source_id'), 'document_chunks', ['source_id'], unique=False)
    op.create_index(op.f('ix_document_chunks_source_type'), 'document_chunks', ['source_type'], unique=False)
    op.create_index(op.f('ix_document_chunks_tenant_id'), 'document_chunks', ['tenant_id'], unique=False)
    
    # Create HNSW vector index for similarity search
    op.execute("""
        CREATE INDEX idx_document_chunks_embedding ON document_chunks 
        USING hnsw (embedding vector_cosine_ops)
    """)
    
    op.create_table('embeddings_jobs',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('tenant_id', sa.BigInteger(), nullable=False),
    sa.Column('module_code', sa.String(length=50), nullable=False),
    sa.Column('job_type', sa.String(length=20), nullable=False),
    sa.Column('source_type', sa.String(length=50), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=False),
    sa.Column('total_items', sa.Integer(), nullable=False),
    sa.Column('processed_items', sa.Integer(), nullable=False),
    sa.Column('failed_items', sa.Integer(), nullable=False),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_jobs_module_status', 'embeddings_jobs', ['module_code', 'status'], unique=False)
    op.create_index('idx_jobs_tenant', 'embeddings_jobs', ['tenant_id', 'created_at'], unique=False)
    op.create_index(op.f('ix_embeddings_jobs_created_at'), 'embeddings_jobs', ['created_at'], unique=False)
    op.create_index(op.f('ix_embeddings_jobs_module_code'), 'embeddings_jobs', ['module_code'], unique=False)
    op.create_index(op.f('ix_embeddings_jobs_status'), 'embeddings_jobs', ['status'], unique=False)
    op.create_index(op.f('ix_embeddings_jobs_tenant_id'), 'embeddings_jobs', ['tenant_id'], unique=False)
    op.create_table('ai_capabilities',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('module_code', sa.String(length=50), nullable=False),
    sa.Column('code', sa.String(length=100), nullable=False),
    sa.Column('name', sa.String(length=200), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('capability_type', sa.String(length=50), nullable=False),
    sa.Column('system_prompt', sa.Text(), nullable=True),
    sa.Column('prompt_template', sa.Text(), nullable=True),
    sa.Column('available_functions', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('default_model', sa.String(length=50), nullable=False),
    sa.Column('default_temperature', sa.Float(), nullable=False),
    sa.Column('default_max_tokens', sa.Integer(), nullable=False),
    sa.Column('required_permission', sa.String(length=100), nullable=True),
    sa.Column('enabled', sa.Boolean(), nullable=False),
    sa.Column('meta_data', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['module_code'], ['ai_modules.code'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_ai_capabilities_capability_type'), 'ai_capabilities', ['capability_type'], unique=False)
    op.create_index(op.f('ix_ai_capabilities_module_code'), 'ai_capabilities', ['module_code'], unique=False)
    op.add_column('conversations', sa.Column('module_code', sa.String(length=50), nullable=False))
    op.add_column('conversations', sa.Column('capability_code', sa.String(length=100), nullable=True))
    op.add_column('conversations', sa.Column('status', sa.String(length=20), nullable=False))
    op.add_column('conversations', sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True))
    op.alter_column('conversations', 'id',
               existing_type=sa.INTEGER(),
               type_=sa.BigInteger(),
               existing_nullable=False,
               autoincrement=True)
    op.alter_column('conversations', 'meta_data',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.drop_index(op.f('idx_context'), table_name='conversations')
    op.drop_index(op.f('idx_user_tenant'), table_name='conversations')
    op.create_index('idx_conv_context', 'conversations', ['context_type', 'context_id'], unique=False)
    op.create_index('idx_conv_module', 'conversations', ['module_code', 'tenant_id'], unique=False)
    op.create_index('idx_conv_tenant_user', 'conversations', ['tenant_id', 'user_id', 'created_at'], unique=False)
    op.create_index(op.f('ix_conversations_context_id'), 'conversations', ['context_id'], unique=False)
    op.create_index(op.f('ix_conversations_context_type'), 'conversations', ['context_type'], unique=False)
    op.create_index(op.f('ix_conversations_created_at'), 'conversations', ['created_at'], unique=False)
    op.create_index(op.f('ix_conversations_module_code'), 'conversations', ['module_code'], unique=False)
    op.create_index(op.f('ix_conversations_status'), 'conversations', ['status'], unique=False)
    op.drop_column('conversations', 'model_type')
    op.add_column('messages', sa.Column('content_type', sa.String(length=20), nullable=False))
    op.add_column('messages', sa.Column('attachments', postgresql.JSONB(astext_type=sa.Text()), nullable=False))
    op.add_column('messages', sa.Column('function_call', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column('messages', sa.Column('model_used', sa.String(length=50), nullable=True))
    op.add_column('messages', sa.Column('processing_time_ms', sa.Integer(), nullable=True))
    op.add_column('messages', sa.Column('sources', postgresql.JSONB(astext_type=sa.Text()), nullable=False))
    op.alter_column('messages', 'id',
               existing_type=sa.INTEGER(),
               type_=sa.BigInteger(),
               existing_nullable=False,
               autoincrement=True)
    op.alter_column('messages', 'meta_data',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.drop_index(op.f('idx_conversation_id'), table_name='messages')
    op.create_index('idx_msg_conversation', 'messages', ['conversation_id', 'created_at'], unique=False)
    op.create_index(op.f('ix_messages_created_at'), 'messages', ['created_at'], unique=False)
    op.create_index(op.f('ix_messages_role'), 'messages', ['role'], unique=False)
    op.drop_column('messages', 'updated_at')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('messages', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False))
    op.drop_index(op.f('ix_messages_role'), table_name='messages')
    op.drop_index(op.f('ix_messages_created_at'), table_name='messages')
    op.drop_index('idx_msg_conversation', table_name='messages')
    op.create_index(op.f('idx_conversation_id'), 'messages', ['conversation_id'], unique=False)
    op.alter_column('messages', 'meta_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('messages', 'id',
               existing_type=sa.BigInteger(),
               type_=sa.INTEGER(),
               existing_nullable=False,
               autoincrement=True)
    op.drop_column('messages', 'sources')
    op.drop_column('messages', 'processing_time_ms')
    op.drop_column('messages', 'model_used')
    op.drop_column('messages', 'function_call')
    op.drop_column('messages', 'attachments')
    op.drop_column('messages', 'content_type')
    op.add_column('conversations', sa.Column('model_type', sa.VARCHAR(length=50), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_conversations_status'), table_name='conversations')
    op.drop_index(op.f('ix_conversations_module_code'), table_name='conversations')
    op.drop_index(op.f('ix_conversations_created_at'), table_name='conversations')
    op.drop_index(op.f('ix_conversations_context_type'), table_name='conversations')
    op.drop_index(op.f('ix_conversations_context_id'), table_name='conversations')
    op.drop_index('idx_conv_tenant_user', table_name='conversations')
    op.drop_index('idx_conv_module', table_name='conversations')
    op.drop_index('idx_conv_context', table_name='conversations')
    op.create_index(op.f('idx_user_tenant'), 'conversations', ['user_id', 'tenant_id'], unique=False)
    op.create_index(op.f('idx_context'), 'conversations', ['context_type', 'context_id'], unique=False)
    op.alter_column('conversations', 'meta_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('conversations', 'id',
               existing_type=sa.BigInteger(),
               type_=sa.INTEGER(),
               existing_nullable=False,
               autoincrement=True)
    op.drop_column('conversations', 'deleted_at')
    op.drop_column('conversations', 'status')
    op.drop_column('conversations', 'capability_code')
    op.drop_column('conversations', 'module_code')
    op.drop_index(op.f('ix_ai_capabilities_module_code'), table_name='ai_capabilities')
    op.drop_index(op.f('ix_ai_capabilities_capability_type'), table_name='ai_capabilities')
    op.drop_table('ai_capabilities')
    op.drop_index(op.f('ix_embeddings_jobs_tenant_id'), table_name='embeddings_jobs')
    op.drop_index(op.f('ix_embeddings_jobs_status'), table_name='embeddings_jobs')
    op.drop_index(op.f('ix_embeddings_jobs_module_code'), table_name='embeddings_jobs')
    op.drop_index(op.f('ix_embeddings_jobs_created_at'), table_name='embeddings_jobs')
    op.drop_index('idx_jobs_tenant', table_name='embeddings_jobs')
    op.drop_index('idx_jobs_module_status', table_name='embeddings_jobs')
    op.drop_table('embeddings_jobs')
    op.drop_index(op.f('ix_document_chunks_tenant_id'), table_name='document_chunks')
    op.drop_index(op.f('ix_document_chunks_source_type'), table_name='document_chunks')
    op.drop_index(op.f('ix_document_chunks_source_id'), table_name='document_chunks')
    op.drop_index(op.f('ix_document_chunks_module_code'), table_name='document_chunks')
    op.drop_index('idx_chunks_tenant_module', table_name='document_chunks')
    op.drop_index('idx_chunks_source', table_name='document_chunks')
    op.drop_table('document_chunks')
    op.drop_index(op.f('ix_ai_modules_code'), table_name='ai_modules')
    op.drop_table('ai_modules')
    
    # Drop pgvector extension
    op.execute('DROP EXTENSION IF EXISTS vector')
    # ### end Alembic commands ###
